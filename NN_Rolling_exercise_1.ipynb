{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x3V4LF17pact"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRtXdEYjpacz"
   },
   "source": [
    "# Neural Network rolling exercise Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0N0NO-zc5lM"
   },
   "source": [
    "In these exercises you will build step by step a complete neural network from scratch using only NumPy (!)<br>\n",
    "In this part we will implement the forward pass of a linear neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwBsNQ1xpacz"
   },
   "source": [
    "# Layer and Network classes implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTXA4aKZpac0"
   },
   "source": [
    "**Question 1:** Implement the Layer class with the following instructions:\n",
    "- Each Layer should contain a matrix weight and a bias vector.\n",
    "- `Layer.apply()` function calculates and returns the layer output using the weights and bias, as we saw in class:\n",
    " - `output = weights @ x_in + bias`\n",
    "- The shapes of the weights matrix and the bias vector are defined as we saw in class:\n",
    " - `weights.shape[0] = #output neurons`\n",
    " - `weights.shape[1] = #input neurons`\n",
    " - `bias.shape[0] = #output neurons`\n",
    "\n",
    "\n",
    " **Hint:** Make sure that the tests given below pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "uLPxSRZzpac0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, weights, bias):\n",
    "        # Initialize the layer with the given weights matrix and bias vector\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def apply(self, x_in):\n",
    "        # Calculate the layer output on the given x_in using layer weights and bias\n",
    "        print('apply w',self.weights,'apply x_in',x_in)\n",
    "        output = np.dot(self.weights, x_in) + self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "WKET-YFiq5S-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply w [[1 0]\n",
      " [0 1]] apply x_in [4 5]\n",
      "apply w [[-1  3]\n",
      " [ 2  2]\n",
      " [ 1  4]] apply x_in [1.  1.5]\n"
     ]
    }
   ],
   "source": [
    "### TESTS FOR LAYER CLASS ###\n",
    "L1 = Layer(np.array([[1, 0], [0, 1]]), bias=np.array([1, 2]))\n",
    "assert (L1.apply(np.array([4, 5])) == np.array([5, 7])).all()\n",
    "L2 = Layer(np.array([[-1, 3], [2, 2], [1, 4]]), bias=np.array([0, 0, -5]))\n",
    "assert (L2.apply(np.array([1., 1.5])) == np.array([3.5, 5., 2.])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBVbCwYqm28e"
   },
   "source": [
    "\n",
    "**Question 2:**\n",
    "Implement the Network class with the following instructions:\n",
    "\n",
    "- Each Network object should contain a list of Layer objects.\n",
    "- Network.forward() function performs a forward-pass given the input data and return the network output:\n",
    " - Iterate over the network's layers\n",
    " - Call the `apply()` function for each layer\n",
    " - Pass the output of each layer as the input to the next layer downstream.\n",
    "\n",
    "\n",
    "\n",
    " **Hint:** Make sure that the tests given below pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RcIGKMjcm7Cc"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers=None):\n",
    "        # Initialize the network with the given layers\n",
    "        if layers is None:\n",
    "            self.layers = []\n",
    "        else:\n",
    "            self.layers = layers\n",
    "\n",
    "    def add_layer(self, new_layer):\n",
    "        # Add a layer to the network\n",
    "        self.layers.append(new_layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Do a forward pass of the network on the given input\n",
    "        # Return the output of the network\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            print('weights',layer.weights,'bias', layer.bias)\n",
    "            output = layer.apply(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "iPvFc3uYskeW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [[1 0]\n",
      " [0 1]] bias [1 2]\n",
      "apply w [[1 0]\n",
      " [0 1]] apply x_in [1.  1.5]\n",
      "weights [[-1  3]\n",
      " [ 2  2]\n",
      " [ 1  4]] bias [ 0  0 -5]\n",
      "apply w [[-1  3]\n",
      " [ 2  2]\n",
      " [ 1  4]] apply x_in [2.  3.5]\n",
      "weights [[1 0]\n",
      " [0 1]] bias [1 2]\n",
      "apply w [[1 0]\n",
      " [0 1]] apply x_in [1.  1.5]\n",
      "weights [[-1  3]\n",
      " [ 2  2]\n",
      " [ 1  4]] bias [ 0  0 -5]\n",
      "apply w [[-1  3]\n",
      " [ 2  2]\n",
      " [ 1  4]] apply x_in [2.  3.5]\n",
      "weights [[ 2  2 -2]] bias [-1]\n",
      "apply w [[ 2  2 -2]] apply x_in [ 8.5 11.  11. ]\n"
     ]
    }
   ],
   "source": [
    "### TESTS FOR NETWORK CLASS ###\n",
    "L1 = Layer(np.array([[1, 0], [0, 1]]), bias=np.array([1, 2]))\n",
    "L2 = Layer(np.array([[-1, 3], [2, 2], [1, 4]]), bias=np.array([0, 0, -5]))\n",
    "N = Network(layers=[L1, L2])\n",
    "assert (N.forward(np.array([1., 1.5])) == np.array([ 8.5, 11. , 11. ])).all()\n",
    "L3 = Layer(np.array([[2, 2, -2]]), bias=np.array([-1]))\n",
    "N.add_layer(L3)\n",
    "assert (N.forward(np.array([1., 1.5])) == np.array([16.])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwXZgZJZpac1"
   },
   "source": [
    "# XOR network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTMZmqtyc5lR"
   },
   "source": [
    "Now it is time to try and implement a __[XOR](https://en.wikipedia.org/wiki/Exclusive_or)__ operator using our neural net implementation.\n",
    "\n",
    "**Questions:**\n",
    "3. Read section 6.1 in __[The Deep Learning Book](https://www.deeplearningbook.org/contents/mlp.html)__ (specifically equations 6.3 to 6.6) \n",
    "4. Initialize a network with two layers with the given weights and biases as specified in the link.\n",
    "5. Use the given input and output of the XOR operator (`xs` and `ys`) and check your network's performance.\n",
    "6. What is the shape of each input? what is the shape of each output? make sure your network receives and outputs numpy arrays with the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Lkbju6Kls2Gf"
   },
   "outputs": [],
   "source": [
    "xs = [\n",
    "  np.array([0,0]),\n",
    "  np.array([0,1]),\n",
    "  np.array([1,0]),\n",
    "  np.array([1,1])\n",
    "]\n",
    "\n",
    "ys = [\n",
    "  np.array([0]),\n",
    "  np.array([1]),\n",
    "  np.array([1]),\n",
    "  np.array([0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "m3X0H4cOpac2"
   },
   "outputs": [],
   "source": [
    "W1 = np.array([[1, 1], [1, 1]])\n",
    "c1 = np.array([0, -1])\n",
    "W2 = np.array([[1] [-2]])\n",
    "c2 = np.array([0])\n",
    "\n",
    "# Initialize the layers of the XOR network\n",
    "layer1 = Layer(W1, bias = c1)\n",
    "layer2 = Layer(W2, bias = np.zeros(1))\n",
    "\n",
    "# Create the network\n",
    "net = Network(layers = [layer1, layer2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "f_CSUnn5pac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [[1 1]\n",
      " [1 1]] bias [ 0 -1]\n",
      "apply w [[1 1]\n",
      " [1 1]] apply x_in [0 0]\n",
      "weights [[ 1]\n",
      " [-2]] bias [0.]\n",
      "apply w [[ 1]\n",
      " [-2]] apply x_in [ 0 -1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# here we check our network performance\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# we go over all of the examples in our dataset and compare the network predicted y to the true y\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(xs, ys):\n\u001b[0;32m----> 4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; expected result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; predicted result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m,layer\u001b[38;5;241m.\u001b[39mweights,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, layer\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m---> 19\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mLayer.apply\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_in):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Calculate the layer output on the given x_in using layer weights and bias\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply w\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply x_in\u001b[39m\u001b[38;5;124m'\u001b[39m,x_in)\n\u001b[0;32m---> 12\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "# here we check our network performance\n",
    "# we go over all of the examples in our dataset and compare the network predicted y to the true y\n",
    "for x, y in zip(xs, ys):\n",
    "    y_pred = net.forward(x)\n",
    "    print(f'input: {x}; expected result: {y}; predicted result: {y_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjZ8mY9gpac4"
   },
   "source": [
    "### Question 7: Can we implement XOR using this network? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZAbjiKyc5lV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN_Rolling_exercise_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
